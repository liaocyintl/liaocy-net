(self.webpackChunkliaocy_net=self.webpackChunkliaocy_net||[]).push([[185],{65565:function(e,n,a){"use strict";a.r(n),a.d(n,{assets:function(){return m},contentTitle:function(){return p},default:function(){return k},frontMatter:function(){return c},metadata:function(){return u},toc:function(){return d}});var t=a(87462),s=a(63366),l=(a(67294),a(3905)),r=a(93456),i=a(13066),o=["components"],c={title:"K8S Memo",authors:"liaocy",tags:["Kubernetes","k8s","k8s-tutorial"]},p=void 0,u={unversionedId:"kubernetes/k8s-memo",id:"kubernetes/k8s-memo",title:"K8S Memo",description:"This is a note of the Kubernetes tutorial.",source:"@site/docs/kubernetes/k8s-memo.mdx",sourceDirName:"kubernetes",slug:"/kubernetes/k8s-memo",permalink:"/liaocy-net/docs/kubernetes/k8s-memo",draft:!1,editUrl:"https://github.com/liaocyintl/liaocy-net/tree/main/docs/kubernetes/k8s-memo.mdx",tags:[{label:"Kubernetes",permalink:"/liaocy-net/docs/tags/kubernetes"},{label:"k8s",permalink:"/liaocy-net/docs/tags/k-8-s"},{label:"k8s-tutorial",permalink:"/liaocy-net/docs/tags/k-8-s-tutorial"}],version:"current",frontMatter:{title:"K8S Memo",authors:"liaocy",tags:["Kubernetes","k8s","k8s-tutorial"]},sidebar:"tutorialSidebar",previous:{title:"Kubernetes",permalink:"/liaocy-net/docs/category/kubernetes"}},m={},d=[{value:"References",id:"references",level:2},{value:"Physical Structure",id:"physical-structure",level:2},{value:"Single Master Node",id:"single-master-node",level:3},{value:"High-Availability Master Nodes",id:"high-availability-master-nodes",level:3},{value:"Build K8S Cluster via Kubeadm",id:"build-k8s-cluster-via-kubeadm",level:2},{value:"OS image",id:"os-image",level:3},{value:"Min Spec",id:"min-spec",level:3},{value:"Install Tools",id:"install-tools",level:3},{value:"Close Firewall",id:"close-firewall",level:3},{value:"Close swap",id:"close-swap",level:3},{value:"Set hostnames",id:"set-hostnames",level:3},{value:"Set hosts",id:"set-hosts",level:3},{value:"Write Kube Traffic in iptables",id:"write-kube-traffic-in-iptables",level:3},{value:"Install Docker",id:"install-docker",level:3},{value:"Install Kubelet",id:"install-kubelet",level:3},{value:"Init Kube Master Node",id:"init-kube-master-node",level:3},{value:"Install flannel plugin",id:"install-flannel-plugin",level:3},{value:"Install Slave Nodes",id:"install-slave-nodes",level:3},{value:"Startup Test Nginx Pod",id:"startup-test-nginx-pod",level:3},{value:"Build K8S Cluster via Binary",id:"build-k8s-cluster-via-binary",level:2},{value:"Ingress Controller",id:"ingress-controller",level:2},{value:"Create Text Pods",id:"create-text-pods",level:3},{value:"Expose Port",id:"expose-port",level:3},{value:"Create Ingress Controller",id:"create-ingress-controller",level:3},{value:"Apply Ingress Controller",id:"apply-ingress-controller",level:3},{value:"HELM",id:"helm",level:2},{value:"Introduce",id:"introduce",level:3},{value:"Usage",id:"usage",level:3},{value:"Install Helm",id:"install-helm",level:3},{value:"Config Helm Repository",id:"config-helm-repository",level:3},{value:"App Deployment",id:"app-deployment",level:3},{value:"Create Chart and Reploy",id:"create-chart-and-reploy",level:3},{value:"charts",id:"charts",level:4},{value:"Chart.yaml",id:"chartyaml",level:4},{value:"templates",id:"templates",level:4},{value:"values.yaml",id:"valuesyaml",level:4},{value:"install chart",id:"install-chart",level:4},{value:"Upgrade Chart",id:"upgrade-chart",level:4},{value:"Templates (Dynamic Parameters)",id:"templates-dynamic-parameters",level:3}],g={toc:d};function k(e){var n=e.components,c=(0,s.Z)(e,o);return(0,l.kt)("wrapper",(0,t.Z)({},g,c,{components:n,mdxType:"MDXLayout"}),(0,l.kt)("p",null,"This is a note of the Kubernetes tutorial."),(0,l.kt)("h2",{id:"references"},"References"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("a",{parentName:"li",href:"https://kubernetes.io/"},"Kubernetes")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("a",{parentName:"li",href:"https://youtu.be/W3V-VgTjDjo"},"Kubernetes tutorial (Chinese)"))),(0,l.kt)("h2",{id:"physical-structure"},"Physical Structure"),(0,l.kt)("h3",{id:"single-master-node"},"Single Master Node"),(0,l.kt)(r.Mermaid,{config:{},chart:"graph LR\n  master[Master 192.168.8.21]\n  node1[Node1 192.168.8.31]\n  node2[Node2 192.168.8.32]\n  node3[Node2 192.168.8.33]\n  master --\x3e node1\n  master --\x3e node2\n  master --\x3e node3",mdxType:"Mermaid"}),(0,l.kt)("h3",{id:"high-availability-master-nodes"},"High-Availability Master Nodes"),(0,l.kt)("h2",{id:"build-k8s-cluster-via-kubeadm"},"Build K8S Cluster via Kubeadm"),(0,l.kt)("h3",{id:"os-image"},"OS image"),(0,l.kt)("p",null,(0,l.kt)("a",{parentName:"p",href:"https://ftp.riken.jp/Linux/centos/7.9.2009/isos/x86_64/"},"CentOS-7-x86_64-Minimal-2009.iso")),(0,l.kt)("h3",{id:"min-spec"},"Min Spec"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Lab environment (Master and Slaves)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"CPU: 2 cores"),(0,l.kt)("li",{parentName:"ul"},"Memory: 2GB"),(0,l.kt)("li",{parentName:"ul"},"Disk: 100GB")))),(0,l.kt)("h3",{id:"install-tools"},"Install Tools"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on all nodes"',title:'"run',on:!0,all:!0,'nodes"':!0},"# Install tools\nyum install -y wget\nyum install -y nano\nyum install -y net-tools\n")),(0,l.kt)("h3",{id:"close-firewall"},"Close Firewall"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on all nodes"',title:'"run',on:!0,all:!0,'nodes"':!0},"systemctl stop firewalld\nsystemctl disable firewalld\n")),(0,l.kt)("h3",{id:"close-swap"},"Close swap"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on all nodes"',title:'"run',on:!0,all:!0,'nodes"':!0},"swapoff -a\nsed -ri 's/.*swap.*/#&/' /etc/fstab\n")),(0,l.kt)("h3",{id:"set-hostnames"},"Set hostnames"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on master"',title:'"run',on:!0,'master"':!0},"hostnamectl set-hostname kube-master\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on node1"',title:'"run',on:!0,'node1"':!0},"hostnamectl set-hostname kube-node1\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on node2"',title:'"run',on:!0,'node2"':!0},"hostnamectl set-hostname kube-node2\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on node3"',title:'"run',on:!0,'node3"':!0},"hostnamectl set-hostname kube-node3\n")),(0,l.kt)("h3",{id:"set-hosts"},"Set hosts"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on master"',title:'"run',on:!0,'master"':!0},"nano /etc/hosts\n")),(0,l.kt)("p",null,"Fill in the following contents:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-text",metastring:'title="/etc/hosts"',title:'"/etc/hosts"'},"192.168.8.21 kube-master\n192.168.8.31 kube-node1\n192.168.8.32 kube-node2\n192.168.8.33 kube-node3\n")),(0,l.kt)("h3",{id:"write-kube-traffic-in-iptables"},"Write Kube Traffic in iptables"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on all nodes"',title:'"run',on:!0,all:!0,'nodes"':!0},"cat <<EOF > /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n\nsysctl --system\n")),(0,l.kt)("h3",{id:"install-docker"},"Install Docker"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on all nodes"',title:'"run',on:!0,all:!0,'nodes"':!0},"yum install -y yum-utils\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nyum install -y docker-ce-18.06.1.ce-3.el7 docker-ce-cli-18.06.1.ce-3.el7 containerd.io docker-compose-plugin\nsystemctl enable docker && systemctl start docker\ndocker --version\n")),(0,l.kt)("h3",{id:"install-kubelet"},"Install Kubelet"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on all nodes"',title:'"run',on:!0,all:!0,'nodes"':!0},"cat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\nEOF\n\nsetenforce 0\nsed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config\n\nyum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0\nsystemctl enable kubelet\n\n")),(0,l.kt)("h3",{id:"init-kube-master-node"},"Init Kube Master Node"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on master"',title:'"run',on:!0,'master"':!0},"kubeadm init --apiserver-advertise-address=192.168.8.21 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16\n\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\nkubectl get nodes\n")),(0,l.kt)("p",null,"The token is only valid for 24-hours. You can use the following command to generate a new token."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubeadm token create --print-join-command\n")),(0,l.kt)("h3",{id:"install-flannel-plugin"},"Install flannel plugin"),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Save as `kube-flannel.yml`"),(0,l.kt)(i.Z,{language:"yaml",mdxType:"CodeBlock"},'---\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: psp.flannel.unprivileged\n  annotations:\n    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default\n    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default\n    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default\n    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default\nspec:\n  privileged: false\n  volumes:\n  - configMap\n  - secret\n  - emptyDir\n  - hostPath\n  allowedHostPaths:\n  - pathPrefix: "/etc/cni/net.d"\n  - pathPrefix: "/etc/kube-flannel"\n  - pathPrefix: "/run/flannel"\n  readOnlyRootFilesystem: false\n  # Users and groups\n  runAsUser:\n    rule: RunAsAny\n  supplementalGroups:\n    rule: RunAsAny\n  fsGroup:\n    rule: RunAsAny\n  # Privilege Escalation\n  allowPrivilegeEscalation: false\n  defaultAllowPrivilegeEscalation: false\n  # Capabilities\n  allowedCapabilities: [\'NET_ADMIN\', \'NET_RAW\']\n  defaultAddCapabilities: []\n  requiredDropCapabilities: []\n  # Host namespaces\n  hostPID: false\n  hostIPC: false\n  hostNetwork: true\n  hostPorts:\n  - min: 0\n    max: 65535\n  # SELinux\n  seLinux:\n    # SELinux is unused in CaaSP\n    rule: \'RunAsAny\'\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: flannel\nrules:\n- apiGroups: [\'extensions\']\n  resources: [\'podsecuritypolicies\']\n  verbs: [\'use\']\n  resourceNames: [\'psp.flannel.unprivileged\']\n- apiGroups:\n  - ""\n  resources:\n  - pods\n  verbs:\n  - get\n- apiGroups:\n  - ""\n  resources:\n  - nodes\n  verbs:\n  - list\n  - watch\n- apiGroups:\n  - ""\n  resources:\n  - nodes/status\n  verbs:\n  - patch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: flannel\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: flannel\nsubjects:\n- kind: ServiceAccount\n  name: flannel\n  namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: flannel\n  namespace: kube-system\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: kube-flannel-cfg\n  namespace: kube-system\n  labels:\n    tier: node\n    app: flannel\ndata:\n  cni-conf.json: |\n    {\n      "name": "cbr0",\n      "cniVersion": "0.3.1",\n      "plugins": [\n        {\n          "type": "flannel",\n          "delegate": {\n            "hairpinMode": true,\n            "isDefaultGateway": true\n          }\n        },\n        {\n          "type": "portmap",\n          "capabilities": {\n            "portMappings": true\n          }\n        }\n      ]\n    }\n  net-conf.json: |\n    {\n      "Network": "10.244.0.0/16",\n      "Backend": {\n        "Type": "vxlan"\n      }\n    }\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-flannel-ds\n  namespace: kube-system\n  labels:\n    tier: node\n    app: flannel\nspec:\n  selector:\n    matchLabels:\n      app: flannel\n  template:\n    metadata:\n      labels:\n        tier: node\n        app: flannel\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      hostNetwork: true\n      priorityClassName: system-node-critical\n      tolerations:\n      - operator: Exists\n        effect: NoSchedule\n      serviceAccountName: flannel\n      initContainers:\n      - name: install-cni-plugin\n       #image: flannelcni/flannel-cni-plugin:v1.1.0 for ppc64le and mips64le (dockerhub limitations may apply)\n        image: rancher/mirrored-flannelcni-flannel-cni-plugin:v1.0.1\n        command:\n        - cp\n        args:\n        - -f\n        - /flannel\n        - /opt/cni/bin/flannel\n        volumeMounts:\n        - name: cni-plugin\n          mountPath: /opt/cni/bin\n      - name: install-cni\n       #image: flannelcni/flannel:v0.18.0 for ppc64le and mips64le (dockerhub limitations may apply)\n        image: rancher/mirrored-flannelcni-flannel:v0.16.3\n        command:\n        - cp\n        args:\n        - -f\n        - /etc/kube-flannel/cni-conf.json\n        - /etc/cni/net.d/10-flannel.conflist\n        volumeMounts:\n        - name: cni\n          mountPath: /etc/cni/net.d\n        - name: flannel-cfg\n          mountPath: /etc/kube-flannel/\n      containers:\n      - name: kube-flannel\n       #image: flannelcni/flannel:v0.18.0 for ppc64le and mips64le (dockerhub limitations may apply)\n        image: rancher/mirrored-flannelcni-flannel:v0.16.3\n        command:\n        - /opt/bin/flanneld\n        args:\n        - --ip-masq\n        - --kube-subnet-mgr\n        resources:\n          requests:\n            cpu: "100m"\n            memory: "50Mi"\n          limits:\n            cpu: "100m"\n            memory: "50Mi"\n        securityContext:\n          privileged: false\n          capabilities:\n            add: ["NET_ADMIN", "NET_RAW"]\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: EVENT_QUEUE_DEPTH\n          value: "5000"\n        volumeMounts:\n        - name: run\n          mountPath: /run/flannel\n        - name: flannel-cfg\n          mountPath: /etc/kube-flannel/\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n      volumes:\n      - name: run\n        hostPath:\n          path: /run/flannel\n      - name: cni-plugin\n        hostPath:\n          path: /opt/cni/bin\n      - name: cni\n        hostPath:\n          path: /etc/cni/net.d\n      - name: flannel-cfg\n        configMap:\n          name: kube-flannel-cfg\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n')),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on master"',title:'"run',on:!0,'master"':!0},"$ kubectl apply -f kube-flannel.yml\n$ kubectl get pods -n kube-system\n$ kubectl get nodes\n")),(0,l.kt)("div",{className:"admonition admonition-warning alert alert--danger"},(0,l.kt)("div",{parentName:"div",className:"admonition-heading"},(0,l.kt)("h5",{parentName:"div"},(0,l.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,l.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,l.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"}))),"Installing flannel plugin may cause some problems.")),(0,l.kt)("div",{parentName:"div",className:"admonition-content"},(0,l.kt)("p",{parentName:"div"},"Referencing ",(0,l.kt)("a",{parentName:"p",href:"https://none06.hatenadiary.org/entry/2022/05/28/025115"},"https://none06.hatenadiary.org/entry/2022/05/28/025115")),(0,l.kt)("pre",{parentName:"div"},(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="Official Kube Flannel Yaml"',title:'"Official',Kube:!0,Flannel:!0,'Yaml"':!0},"wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\nnano kube-flannel.yml\n")),(0,l.kt)("p",{parentName:"div"},(0,l.kt)("img",{alt:"alt",src:a(26906).Z,title:"title",width:"706",height:"500"})))),(0,l.kt)("h3",{id:"install-slave-nodes"},"Install Slave Nodes"),(0,l.kt)("p",null,"This command should be copied from the contents that the master node generated."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on slave nodes"',title:'"run',on:!0,slave:!0,'nodes"':!0}," kubeadm join 192.168.8.21:6443 --token fxm6sy.jsw1uyarkx2fzsnw \\\n    --discovery-token-ca-cert-hash sha256:77c6f969d3e43942e4dea3b3c413ac9178fe89a2a6ac1a98254593eba574719e\n")),(0,l.kt)("h3",{id:"startup-test-nginx-pod"},"Startup Test Nginx Pod"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on master"',title:'"run',on:!0,'master"':!0},"kubectl create deployment nginx --image=nginx\nkubectl get pods\nkubectl expose deployment nginx --port=80 --type=NodePort\nkubectl get pod, svc\nkubectl get pods -A -o wide\n")),(0,l.kt)("p",null,"Then you can access the Nginx service via the URL from any node."),(0,l.kt)("p",null,"http://<node_ip>:<exposed_port>/"),(0,l.kt)("h2",{id:"build-k8s-cluster-via-binary"},"Build K8S Cluster via Binary"),(0,l.kt)("p",null,"pending"),(0,l.kt)("h2",{id:"ingress-controller"},"Ingress Controller"),(0,l.kt)("p",null,"Ingress Controller is a Kubernetes add-on that provides a simple way to expose your services to the internet."),(0,l.kt)("h3",{id:"create-text-pods"},"Create Text Pods"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create deployment web --image=nginx\nkubectl get pods -o wide\n\n# NAME                   READY   STATUS              RESTARTS   AGE   IP       NODE         NOMINATED NODE   READINESS GATES\n# web-5dcb957ccc-px72n   0/1     ContainerCreating   0          7s    <none>   kube-node1   <none>           <none>\n\n")),(0,l.kt)("h3",{id:"expose-port"},"Expose Port"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"\nkubectl expose deployment web --port=80 --target-port=80 --type=NodePort\n\nkubectl get svc\n\n# NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n# kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        3d14h\n# web          NodePort    10.109.213.80   <none>        80:30622/TCP   70s\n\n")),(0,l.kt)("h3",{id:"create-ingress-controller"},"Create Ingress Controller"),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Save as `ingress-controller.yml`"),(0,l.kt)(i.Z,{language:"yaml",mdxType:"CodeBlock"},'apiVersion: v1\nkind: Namespace\nmetadata:\n  name: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: nginx-configuration\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: tcp-services\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: udp-services\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: nginx-ingress-serviceaccount\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRole\nmetadata:\n  name: nginx-ingress-clusterrole\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nrules:\n  - apiGroups:\n      - ""\n    resources:\n      - configmaps\n      - endpoints\n      - nodes\n      - pods\n      - secrets\n    verbs:\n      - list\n      - watch\n  - apiGroups:\n      - ""\n    resources:\n      - nodes\n    verbs:\n      - get\n  - apiGroups:\n      - ""\n    resources:\n      - services\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - "extensions"\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - ""\n    resources:\n      - events\n    verbs:\n      - create\n      - patch\n  - apiGroups:\n      - "extensions"\n    resources:\n      - ingresses/status\n    verbs:\n      - update\n\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: Role\nmetadata:\n  name: nginx-ingress-role\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nrules:\n  - apiGroups:\n      - ""\n    resources:\n      - configmaps\n      - pods\n      - secrets\n      - namespaces\n    verbs:\n      - get\n  - apiGroups:\n      - ""\n    resources:\n      - configmaps\n    resourceNames:\n      # Defaults to "<election-id>-<ingress-class>"\n      # Here: "<ingress-controller-leader>-<nginx>"\n      # This has to be adapted if you change either parameter\n      # when launching the nginx-ingress-controller.\n      - "ingress-controller-leader-nginx"\n    verbs:\n      - get\n      - update\n  - apiGroups:\n      - ""\n    resources:\n      - configmaps\n    verbs:\n      - create\n  - apiGroups:\n      - ""\n    resources:\n      - endpoints\n    verbs:\n      - get\n\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: RoleBinding\nmetadata:\n  name: nginx-ingress-role-nisa-binding\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: nginx-ingress-role\nsubjects:\n  - kind: ServiceAccount\n    name: nginx-ingress-serviceaccount\n    namespace: ingress-nginx\n\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: nginx-ingress-clusterrole-nisa-binding\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: nginx-ingress-clusterrole\nsubjects:\n  - kind: ServiceAccount\n    name: nginx-ingress-serviceaccount\n    namespace: ingress-nginx\n\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-ingress-controller\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: ingress-nginx\n      app.kubernetes.io/part-of: ingress-nginx\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: ingress-nginx\n        app.kubernetes.io/part-of: ingress-nginx\n      annotations:\n        prometheus.io/port: "10254"\n        prometheus.io/scrape: "true"\n    spec:\n      hostNetwork: true\n      serviceAccountName: nginx-ingress-serviceaccount\n      containers:\n        - name: nginx-ingress-controller\n          image: siriuszg/nginx-ingress-controller:0.20.0\n          args:\n            - /nginx-ingress-controller\n            - --configmap=$(POD_NAMESPACE)/nginx-configuration\n            - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\n            - --udp-services-configmap=$(POD_NAMESPACE)/udp-services\n            - --publish-service=$(POD_NAMESPACE)/ingress-nginx\n            - --annotations-prefix=nginx.ingress.kubernetes.io\n          securityContext:\n            allowPrivilegeEscalation: true\n            capabilities:\n              drop:\n                - ALL\n              add:\n                - NET_BIND_SERVICE\n            # www-data -> 33\n            runAsUser: 33\n          env:\n            - name: POD_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.name\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n          ports:\n            - name: http\n              containerPort: 80\n            - name: https\n              containerPort: 443\n          livenessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            initialDelaySeconds: 10\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 10\n          readinessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 10\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: ingress-nginx\n  namespace: ingress-nginx\nspec:\n  #type: NodePort\n  ports:\n    - name: http\n      port: 80\n      targetPort: 80\n      protocol: TCP\n    - name: https\n      port: 443\n      targetPort: 443\n      protocol: TCP\n  selector:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx')),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="run on master"',title:'"run',on:!0,'master"':!0},"kubectl apply -f ingress-controller.yml \n\n# namespace/ingress-nginx created\n# configmap/nginx-configuration created\n# configmap/tcp-services created\n# configmap/udp-services created\n# serviceaccount/nginx-ingress-serviceaccount created\n# clusterrole.rbac.authorization.k8s.io/nginx-ingress-clusterrole created\n# role.rbac.authorization.k8s.io/nginx-ingress-role created\n# rolebinding.rbac.authorization.k8s.io/nginx-ingress-role-nisa-binding created\n# clusterrolebinding.rbac.authorization.k8s.io/nginx-ingress-clusterrole-nisa-binding created\n# daemonset.apps/nginx-ingress-controller created\n# service/ingress-nginx created\n\n")),(0,l.kt)("h3",{id:"apply-ingress-controller"},"Apply Ingress Controller"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pods -n ingress-nginx\n\n# NAME                             READY   STATUS              RESTARTS   AGE\n# nginx-ingress-controller-57wqf   0/1     ContainerCreating   0          111s\n# nginx-ingress-controller-5spw2   0/1     Running             0          111s\n# nginx-ingress-controller-kk552   0/1     ContainerCreating   0          111s\n")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Save as `ingress.yml`"),(0,l.kt)(i.Z,{language:"yaml",mdxType:"CodeBlock"},"apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: example-ingress\nspec:\n  rules:\n  - host: example.ingredemo.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName:\n          servicePort: 80")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f ingress.yaml \n# ingress.networking.k8s.io/example-ingress created\n\nkubectl get ing\n# NAME              CLASS    HOSTS                   ADDRESS   PORTS   AGE\n# example-ingress   <none>   example.ingredemo.com             80      5m52s\n")),(0,l.kt)("p",null,"Then you can access the service with the ",(0,l.kt)("inlineCode",{parentName:"p"},"example.ingredemo.com"),"."),(0,l.kt)("div",{className:"admonition admonition-warning alert alert--danger"},(0,l.kt)("div",{parentName:"div",className:"admonition-heading"},(0,l.kt)("h5",{parentName:"div"},(0,l.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,l.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,l.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"}))),"warning")),(0,l.kt)("div",{parentName:"div",className:"admonition-content"},(0,l.kt)("p",{parentName:"div"},(0,l.kt)("inlineCode",{parentName:"p"},"example.ingredemo.com")," should be specified as the IP of any slave node."))),(0,l.kt)("h2",{id:"helm"},"HELM"),(0,l.kt)("h3",{id:"introduce"},"Introduce"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"helm: a package manager for Kubernetes")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Chart: a collection of Kubernetes resources")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Release: version controll"))),(0,l.kt)("h3",{id:"usage"},"Usage"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Manage YAML"),(0,l.kt)("li",{parentName:"ul"},"Reuse YAML"),(0,l.kt)("li",{parentName:"ul"},"Version Control")),(0,l.kt)("h3",{id:"install-helm"},"Install Helm"),(0,l.kt)("p",null,"Ref: ",(0,l.kt)("a",{parentName:"p",href:"https://helm.sh/docs/intro/quickstart/"},"https://helm.sh/docs/intro/quickstart/")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://get.helm.sh/helm-v3.9.0-linux-amd64.tar.gz\ntar zxvf helm-v3.9.0-linux-amd64.tar.gz\ncp linux-amd64/helm /usr/bin/\nhelm version\n")),(0,l.kt)("h3",{id:"config-helm-repository"},"Config Helm Repository"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"helm repo add stable https://charts.helm.sh/stable\nhelm repo add alicloud https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts\nhelm repo list\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="update repo"',title:'"update','repo"':!0},"helm repo update\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="remove repo"',title:'"remove','repo"':!0},"helm repo remove alicloud\n")),(0,l.kt)("h3",{id:"app-deployment"},"App Deployment"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"helm search repo weave\n# NAME                    CHART VERSION   APP VERSION     DESCRIPTION                                       \n# stable/weave-cloud      0.3.9           1.4.0           DEPRECATED - Weave Cloud is a add-on to Kuberne...\n# stable/weave-scope      1.1.12          1.12.0          DEPRECATED - A Helm chart for the Weave Scope c...\nhelm install ui stable/weave-scope\nhelm list\nhelm status ui\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="Check Service and Expose Port"',title:'"Check',Service:!0,and:!0,Expose:!0,'Port"':!0},"kubectl get svc\n# NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n# ui-weave-scope   ClusterIP   10.97.190.230   <none>        80/TCP         3m31s\nkubectl edit svc ui-weave-scope\n# Change 'type: ClusterIP' into 'type: NodePort'\nkubectl get svc\nNAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n# ui-weave-scope   NodePort    10.97.190.230   <none>        80:32320/TCP   5m55s\n")),(0,l.kt)("h3",{id:"create-chart-and-reploy"},"Create Chart and Reploy"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"helm create mychart\n# Creating mychart\nls mychart/\n# charts  Chart.yaml  templates  values.yaml\ncd mychart/\n")),(0,l.kt)("h4",{id:"charts"},"charts"),(0,l.kt)("h4",{id:"chartyaml"},"Chart.yaml"),(0,l.kt)("p",null,"Current chart attributes."),(0,l.kt)("h4",{id:"templates"},"templates"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"cd templates/\nrm -rf *\n\nkubectl create deployment web1 --image=nginx --dry-run=client -o yaml > deployment.yaml\n\nkubectl create deployment web1 --image=nginx\nkubectl expose deployment web1 --port=80 --target-port=80 --type=NodePort --dry-run=client -o yaml > service.yaml\nkubectl delete deployment web1\n")),(0,l.kt)("h4",{id:"valuesyaml"},"values.yaml"),(0,l.kt)("p",null,"Some global variables are used in the templates."),(0,l.kt)("h4",{id:"install-chart"},"install chart"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"cd /root/\nhelm install web1 mychart/\n# NAME: web1\n# LAST DEPLOYED: Wed Jun  8 06:51:05 2022\n# NAMESPACE: default\n# STATUS: deployed\n# REVISION: 1\n# TEST SUITE: None\n\nkubectl get pods -o wide\n# NAME                                            READY   STATUS    RESTARTS   AGE     IP             NODE          NOMINATED NODE   READINESS GATES\n# web1-7f87dfbd56-pz6wh                           1/1     Running   0          31s     10.244.4.72    kube-node3    <none>           <none>\n\nkubectl get svc\n# NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n# web1             NodePort    10.97.201.222   <none>        80:31459/TCP   76s\n")),(0,l.kt)("h4",{id:"upgrade-chart"},"Upgrade Chart"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},'helm upgrade web1 mychart/\n# Release "web1" has been upgraded. Happy Helming!\n# NAME: web1\n# LAST DEPLOYED: Wed Jun  8 06:54:14 2022\n# NAMESPACE: default\n# STATUS: deployed\n# REVISION: 2\n# TEST SUITE: None\n')),(0,l.kt)("h3",{id:"templates-dynamic-parameters"},"Templates (Dynamic Parameters)"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"cd /root/mychart/\n")),(0,l.kt)("p",null,"Change ",(0,l.kt)("inlineCode",{parentName:"p"},"values.yaml")," as following:"),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Save as `values.yaml`"),(0,l.kt)(i.Z,{language:"yaml",mdxType:"CodeBlock"},'# Default values for mychart.\n# This is a YAML-formatted file.\n# Declare variables to be passed into your templates.\n\nreplicaCount: 1\n\nimage: nginx\ntag: 1.1\nlabel: nginx\nport: 80\n\nimagePullSecrets: []\nnameOverride: ""\nfullnameOverride: ""\n\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: true\n  # Annotations to add to the service account\n  annotations: {}\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: ""\n\npodAnnotations: {}\n\npodSecurityContext: {}\n  # fsGroup: 2000\n\nsecurityContext: {}\n  # capabilities:\n  #   drop:\n  #   - ALL\n  # readOnlyRootFilesystem: true\n  # runAsNonRoot: true\n  # runAsUser: 1000\n\nservice:\n  type: ClusterIP\n  port: 80\n\ningress:\n  enabled: false\n  className: ""\n  annotations: {}\n    # kubernetes.io/ingress.class: nginx\n    # kubernetes.io/tls-acme: "true"\n  hosts:\n    - host: chart-example.local\n      paths:\n        - path: /\n          pathType: ImplementationSpecific\n  tls: []\n  #  - secretName: chart-example-tls\n  #    hosts:\n  #      - chart-example.local\n\nresources: {}\n  # We usually recommend not to specify default resources and to leave this as a conscious\n  # choice for the user. This also increases chances charts run on environments with little\n  # resources, such as Minikube. If you do want to specify resources, uncomment the following\n  # lines, adjust them as necessary, and remove the curly braces after \'resources:\'.\n  # limits:\n  #   cpu: 100m\n  #   memory: 128Mi\n  # requests:\n  #   cpu: 100m\n  #   memory: 128Mi\n\nautoscaling:\n  enabled: false\n  minReplicas: 1\n  maxReplicas: 100\n  targetCPUUtilizationPercentage: 80\n  # targetMemoryUtilizationPercentage: 80\n\nnodeSelector: {}\n\ntolerations: []\n\naffinity: {}')),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"cd mychart/templates/\n\n")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Save as `deployment.yaml`"),(0,l.kt)(i.Z,{language:"yaml",mdxType:"CodeBlock"},"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  creationTimestamp: null\n  labels:\n    app: {{ .Release.Name}}\n  name: {{ .Release.Name}}-deploy\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: {{ .Values.label}}\n  strategy: {}\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: {{ .Values.label}}   \n    spec:\n      containers:\n      - image: {{ .Values.image}}\n        name: nginx\n        resources: {}\nstatus: {}")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},'cd /root\nhelm install --dry-run web2 mychart/\nhelm install web2 mychart/\n# Release "web2" has been upgraded. Happy Helming!\n# NAME: web2\n# LAST DEPLOYED: Wed Jun  8 07:15:51 2022\n# NAMESPACE: default\n# STATUS: deployed\n# REVISION: 1\n# TEST SUITE: None\n\nkubectl get pods\n# NAME                                            READY   STATUS    RESTARTS   AGE\n# web2-deploy-f89759699-9lkgw                     1/1     Running   0          59s\n\nkubectl get svc\n# NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n# web2-svc         NodePort    10.97.103.186   <none>        80:31374/TCP   44s\n')))}k.isMDXComponent=!0},11748:function(e,n,a){var t={"./locale":89234,"./locale.js":89234};function s(e){var n=l(e);return a(n)}function l(e){if(!a.o(t,e)){var n=new Error("Cannot find module '"+e+"'");throw n.code="MODULE_NOT_FOUND",n}return t[e]}s.keys=function(){return Object.keys(t)},s.resolve=l,e.exports=s,s.id=11748},26906:function(e,n,a){"use strict";n.Z=a.p+"assets/images/2022-06-06-11-01-22-ae45c939ca7d9d1df37b160b2daa92ad.png"}}]);